{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Reading and writing a local N5 dataset"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Create a new N5 dataset on the local filesystem using the file Key-Value Store driver :"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import tensorstore as ts\n",
    "import numpy as np\n",
    "dataset = ts.open({\n",
    "        'driver': 'n5',\n",
    "    'kvstore': {\n",
    "            'driver': 'file',\n",
    "        'path': 'tmp/dataset/',\n",
    "    },\n",
    "    'metadata': {\n",
    "            'compression': {\n",
    "                'type': 'gzip'\n",
    "        },\n",
    "        'dataType': 'uint32',\n",
    "        'dimensions': [1000, 20000],\n",
    "        'blockSize': [100, 100],\n",
    "    },\n",
    "    'create': True,\n",
    "    'delete_existing': True,\n",
    "}).result()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Asynchronously write to a sub-region :"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "write_future = dataset[80:82, 99:102].write([[1, 2, 3], [4, 5, 6]])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Wait for the write to complete using tensorstore.Future.result :"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "write_future.result()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In an async function (or with top-level await support), await can also be used for interoperability with asyncio :"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "await write_future"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Subscript assignment can aslo be used to write synchronously"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dataset[80:82, 99:102] = [[1, 2, 3], [4, 5, 6]]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Read back a larger region that contains the region that was written (positions not written have the fill value of 0):"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dataset[0:1000, 0:20000].read().result().shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Reading the Janelia FlyEM Hemibrain dataset"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This example demonstrates accessing the Janelia FlyeEM Hemibrain 1.1 segmentation using the neuroglancer_precomputed Driver.\n",
    "\n",
    "While this dataset is public, the gcs Key-Value Store driver currently requires that you supply Google Cloud credentials.\n",
    "\n",
    "Open the dataset asynchronously to obtain a tensorstore.Future:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import tensorstore as ts\n",
    "import numpy as np\n",
    "dataset_future = ts.open({\n",
    "    'driver':\n",
    "        'neuroglancer_precomputed',\n",
    "    'kvstore':\n",
    "        'gs://neuroglancer-janelia-flyem-hemibrain/v1.1/segmentation/',\n",
    "    # Use 100MB in-memory cache.\n",
    "    'context': {\n",
    "        'cache_pool': {\n",
    "            'total_bytes_limit': 100_000_000\n",
    "        }\n",
    "    },\n",
    "    'recheck_cached_data':\n",
    "        'open',\n",
    "})\n",
    "dataset_future"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "wait for the open to complete:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dataset = dataset_future.result()\n",
    "dataset"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In an async function, a tensorstore.Future is also compatible with await."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dataset = await dataset_future"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dataset.domain"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "There is only a single channel, so create a 3-d view without the 'channel' dimension:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dataset_3d = dataset[ts.d['channel'][0]]\n",
    "dataset_3d.domain"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Create a view of a 100x100x1 slice from the middle, without performing any I/O:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "x = dataset_3d[15000:15100, 15000:15100, 20000]\n",
    "x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "x.domain"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Read the slice asynchronously using the tensorstore.TensorStore.read method to obtain a tensorstore.Future:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "read_future = x.read()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Wait for the read to complete:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "read_future.result()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Conversion to an numpy.ndarray also implicitly performs a synchronous read (which hits the in-memory cache since the same region was just retrieved):"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "np.array(dataset_3d[15000:15100, 15000:15100, 20000])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "store = await ts.open(\n",
    "    {\n",
    "        'driver': 'zarr',\n",
    "        'kvstore': {\n",
    "            'driver': 'memory'\n",
    "        }\n",
    "    },\n",
    "    create=True,\n",
    "    shape=[100],\n",
    "    dtype=ts.uint32,\n",
    "    fill_value=42)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "store.read().result()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "store = await ts.open(\n",
    "    {\n",
    "        'driver': 'n5',\n",
    "        'kvstore': {\n",
    "            'driver': 'memory'\n",
    "        }\n",
    "    },\n",
    "    create=True,\n",
    "    shape=[100, 200],\n",
    "    dtype=ts.uint32,\n",
    "    dimension_units=['5nm', '8nm'])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "store + np.array(0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dataset = ts.open({\n",
    "    'driver': 'zarr',\n",
    "    'kvstore': {\n",
    "        'driver': 'memory'\n",
    "    }\n",
    "},\n",
    "                  dtype=ts.uint32,\n",
    "                  shape=[2, 70, 80],\n",
    "                  create=True).result()\n",
    "dataset.vindex[:, [5, 6, 8], [2, 5, 6]] = [[1, 2], [3, 4], [5, 6]]\n",
    "dataset[:, 5:10, 0:6].read().result()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X = store.transaction"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3.10.4 ('tensorstore')",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.4"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "ea92185c205064e53b8424dc6e2af8940846dda10ca2f988cd1e0b65031f4846"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
